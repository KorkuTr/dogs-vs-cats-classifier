{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3362,"databundleVersionId":31148,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Gerekli Kütüphanelerin Yüklenmesi (Setup)\n\nBu bölümde, projemiz için gerekli olan tüm Python kütüphanelerini (paketlerini) içe aktaracağız.\n\n* **Pandas ve NumPy:** Veri manipülasyonu ve sayısal işlemler için.\n* **Matplotlib ve Seaborn:** Veri görselleştirme ve grafikleri oluşturmak için.\n* **PIL (Pillow):** Görüntü işleme ve yükleme işlemleri için.\n* **Os:** Dosya sistemi ve dizinlerle çalışmak için.\n\nBu adım, tüm araçlarımızın çalışmaya hazır olmasını sağlar.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-24T20:14:20.576863Z","iopub.execute_input":"2025-09-24T20:14:20.577260Z","iopub.status.idle":"2025-09-24T20:14:21.775691Z","shell.execute_reply.started":"2025-09-24T20:14:20.577223Z","shell.execute_reply":"2025-09-24T20:14:21.774852Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Veri Seti Hazırlığı: Dosya Yolları ve Çıkarma\nBu bölümde, Görüntü Sınıflandırma modelimizi eğiteceğimiz Dogs vs. Cats veri setini Kaggle ortamından alıp kullanıma hazır hale getiriyoruz. Veri seti zip formatında olduğu için, öncelikle dosyaları çıkarıp klasör yapımızı oluşturacağız.\n\nAmaç: Zip dosyalarını açmak ve görüntü dosyalarının yollarını belirlemek.\n\nKullanılan Kütüphaneler: zipfile (sıkıştırılmış dosyalar için) ve os (dizin işlemleri için).\n\n# 2.1 Zip Dosyalarının Çıkarılması ve Klasör Yapısının Oluşturulması\n\nAşağıdaki kod bloğunda, eğitim (train.zip) ve test (test1.zip) verilerini /kaggle/working/ dizininde oluşturduğumuz yeni klasörlere çıkarıyoruz. Bu sayede, modelimiz dosyalara doğrudan erişebilecektir.","metadata":{}},{"cell_type":"code","source":"import zipfile # zipfile kütüphanesini içe aktar\n\n# Zip dosyalarının yollarını belirle\n# Not: 'test.zip' yerine 'test1.zip' olarak güncelledim\ntrain_zip_path = '/kaggle/input/dogs-vs-cats/train.zip'\ntest_zip_path = '/kaggle/input/dogs-vs-cats/test1.zip' # Eğer test1.zip ise\n\n# Çıkarılacak dizinleri belirle\noutput_dir = '/kaggle/working/dogs_vs_cats_unzipped/' # Çıkarılan dosyaların kaydedileceği yer\n\n# Çıkarılacak dizinleri oluştur (eğer yoksa)\nos.makedirs(output_dir, exist_ok=True)\nos.makedirs(os.path.join(output_dir, 'train'), exist_ok=True)\nos.makedirs(os.path.join(output_dir, 'test'), exist_ok=True)\n\n\nprint(\"Eğitim verileri çıkarılıyor...\")\nwith zipfile.ZipFile(train_zip_path, 'r') as zip_ref:\n    zip_ref.extractall(os.path.join(output_dir, 'train')) # train klasörüne çıkar\n\nprint(\"Test verileri çıkarılıyor...\")\nwith zipfile.ZipFile(test_zip_path, 'r') as zip_ref:\n    zip_ref.extractall(os.path.join(output_dir, 'test')) # test klasörüne çıkar\n\nprint(\"Tüm veriler başarıyla çıkarıldı.\")\n\n# --- Veri Yollarını KESİNLEŞTİRME ---\n# Eğitim klasörü için: output_dir/train/train/\ntrain_images_dir = os.path.join(output_dir, 'train', 'train')\n\n# Test klasörü için: output_dir/test/test1/\ntest_images_dir = os.path.join(output_dir, 'test', 'test1')\n\n# --- Şimdi dosya isimlerini alabiliriz ---\ntrain_filenames = os.listdir(train_images_dir)\ntest_filenames = os.listdir(test_images_dir)\n\n\n# Güncellenmiş klasörlerdeki dosya sayılarını kontrol edelim\nprint(f\"Kesinleştirilmiş eğitim setindeki görsel sayısı: {len(train_filenames)}\")\nprint(f\"Kesinleştirilmiş test setindeki görsel sayısı: {len(test_filenames)}\")\n\nprint(\"\\nKesinleştirilmiş eğitim klasöründeki ilk 5 dosya:\")\nprint(train_filenames[:5])\n\nprint(\"\\nKesinleştirilmiş test klasöründeki ilk 5 dosya:\")\nprint(test_filenames[:5])\n\n# --- Veri Çerçevesi Oluşturma (Eğitim Seti İçin) ---\n# Görüntü dosyalarından etiketleri (dog/cat) çıkaralım\ndef extract_label(filename):\n    if 'cat' in filename:\n        return 'cat'\n    elif 'dog' in filename:\n        return 'dog'\n    return 'unknown' # Test setinde bu kullanılmayacak, sadece train için\n\ntrain_data = []\nfor filename in train_filenames:\n    label = extract_label(filename)\n    train_data.append({'filename': filename, 'label': label})\n\ntrain_df = pd.DataFrame(train_data)\n\nprint(\"\\nEğitim veri çerçevesinin ilk 5 satırı:\")\nprint(train_df.head())\n\nprint(\"\\nEğitim veri çerçevesindeki etiket dağılımı:\")\nprint(train_df['label'].value_counts())\n\n# Test setinde etiket olmadığı için sadece dosya isimlerini içeren bir dataframe oluşturalım\ntest_data = []\nfor filename in test_filenames:\n    test_data.append({'filename': filename})\n\ntest_df = pd.DataFrame(test_data)\nprint(\"\\nTest veri çerçevesinin ilk 5 satırı:\")\nprint(test_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T20:14:21.776960Z","iopub.execute_input":"2025-09-24T20:14:21.777276Z","iopub.status.idle":"2025-09-24T20:14:35.434156Z","shell.execute_reply.started":"2025-09-24T20:14:21.777257Z","shell.execute_reply":"2025-09-24T20:14:35.433275Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  3. Veri Ön İnceleme (Data Inspection)\nYukarıdaki kod bloğunda, yalnızca dosyaları çıkarmakla kalmadık, aynı zamanda model eğitiminde kullanacağımız iki ana Pandas DataFrame'i (train_df ve test_df) oluşturduk.\n\nŞimdi bu DataFrame'leri kullanarak Keşifçi Veri Analizi (EDA) aşamasına geçmeden önce son bir kontrol yapalım.\n\n # 3.1 Görüntü Sınıf Dağılımının Görselleştirilmesi\nEğitim setimizdeki kedi ve köpek görüntülerinin sayılarının dengeli olup olmadığını kontrol etmek, modelin taraflı öğrenmesini engellemek adına önemlidir. value_counts() çıktısını grafik üzerinde görselleştirelim.","metadata":{}},{"cell_type":"markdown","source":"# 4. Keşifçi Veri Analizi (EDA) ve Görsel İnceleme\nBu bölümde, modelimizi eğitmeden önce veri setimiz hakkında derinlemesine bilgi edineceğiz. Görüntü boyutları, sınıfların dağılımı ve rastgele örnekler gibi temel istatistikleri görselleştirerek veriyi \"tanıyacağız\".\n\n# 4.1 Eğitim Setinden Rastgele Örneklerin İncelenmesi\nGörüntü kalitesini, olası gürültüyü veya ilginç özellikleri görmek için eğitim setinden rastgele seçilen 9 örneği matris halinde gösteriyoruz. Her görselin başlığında etiketini (cat veya dog) ve piksel boyutlarını görebiliriz. Bu, veri setindeki çeşitliliği ve boyut farklılıklarını anlamamıza yardımcı olur.","metadata":{}},{"cell_type":"code","source":"\n# Adım 5: Verileri Görselleştirme ve Temel İstatistikler\n\n# 5.1 Eğitim setinden rastgele birkaç görüntü gösterelim\nprint(\"\\nEğitim setinden rastgele 9 örnek görüntü:\")\nplt.figure(figsize=(12, 12))\nfor i in range(9):\n    random_index = np.random.randint(0, len(train_df))\n    filename = train_df.iloc[random_index]['filename']\n    label = train_df.iloc[random_index]['label']\n    img_path = os.path.join(train_images_dir, filename)\n\n    img = Image.open(img_path)\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(img)\n    plt.title(f\"{label} - {img.size[0]}x{img.size[1]}\")\n    plt.axis('off')\nplt.tight_layout() # Görsellerin çakışmasını engeller\nplt.show()\n\n# Burada gösterdiğimiz rastgele kedi ve köpek görsellerinin bir benzerini oluşturalım.\n# Her bir görselde bir kedi ya da köpek olacak, başlığında türü ve boyutları yazacak.\n# Çözünürlük ve renkler rastgele olabilir.\nprint(\"\\nGördüğümüz rastgele kedi ve köpek görsellerine benzer bir örnek: \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T20:14:35.435054Z","iopub.execute_input":"2025-09-24T20:14:35.435375Z","iopub.status.idle":"2025-09-24T20:14:36.923852Z","shell.execute_reply.started":"2025-09-24T20:14:35.435347Z","shell.execute_reply":"2025-09-24T20:14:36.922573Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4.3 Görüntü Boyutlarının Detaylı Analizi\nÖnceki adımlarda gördüğümüz gibi, veri setimizdeki görüntüler tek bir boyutta değil, çok çeşitli çözünürlüklere sahiptir. Derin öğrenme modelleri genellikle sabit boyutlu (örneğin 224x224 veya 256x256) girdiler gerektirdiğinden, bu boyut dağılımını detaylıca anlamamız kritik öneme sahiptir.\n\nAşağıdaki kod bloğunda, tüm eğitim görüntülerinin genişlik ve yükseklik değerlerini toplayıp:\n\nTemel İstatistikleri (min, max, mean, std) inceliyoruz.\n\nDağılımlarını (histogramlar) görselleştiriyoruz.\n\nEn sık karşılaşılan boyutları listeliyoruz.\n\nBu analiz, bir sonraki aşamada uygulayacağımız yeniden boyutlandırma (resizing) stratejisine yön verecektir.","metadata":{}},{"cell_type":"code","source":"# Adım 6: Görüntü Boyutlarının Analizi\n\n# Eğitim setindeki görüntü boyutlarını toplayalım\nimage_sizes = []\nfor filename in train_filenames:\n    try:\n        img_path = os.path.join(train_images_dir, filename)\n        with Image.open(img_path) as img:\n            image_sizes.append(img.size) # (width, height)\n    except Exception as e:\n        print(f\"Hata oluştu: {filename} - {e}\")\n        # Hatalı veya bozuk dosyaları atla\n\n# Boyutları bir DataFrame'e dönüştürelim\nsize_df = pd.DataFrame(image_sizes, columns=['width', 'height'])\n\nprint(\"\\nGörüntü boyutlarının ilk 5 satırı:\")\nprint(size_df.head())\n\nprint(\"\\nGörüntü boyutlarının temel istatistikleri:\")\nprint(size_df.describe())\n\n# Genişlik ve yükseklik dağılımını görselleştirelim\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nsns.histplot(size_df['width'], bins=50, kde=True)\nplt.title('Görüntü Genişliği Dağılımı')\nplt.xlabel('Genişlik (piksel)')\nplt.ylabel('Sayı')\n\nplt.subplot(1, 2, 2)\nsns.histplot(size_df['height'], bins=50, kde=True)\nplt.title('Görüntü Yüksekliği Dağılımı')\nplt.xlabel('Yükseklik (piksel)')\nplt.ylabel('Sayı')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nEn sık görülen görüntü boyutları (ilk 10):\")\nprint(size_df.value_counts().head(10))\n\n# En küçük ve en büyük boyutları da görmek faydalı olabilir\nprint(f\"\\nEn küçük genişlik: {size_df['width'].min()}, En küçük yükseklik: {size_df['height'].min()}\")\nprint(f\"En büyük genişlik: {size_df['width'].max()}, En büyük yükseklik: {size_df['height'].max()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T20:14:36.926185Z","iopub.execute_input":"2025-09-24T20:14:36.926830Z","iopub.status.idle":"2025-09-24T20:14:39.670138Z","shell.execute_reply.started":"2025-09-24T20:14:36.926794Z","shell.execute_reply":"2025-09-24T20:14:39.669482Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Veri Ön İşleme ve Hazırlık (Data Preprocessing & Augmentation)\nÖnceki analizlerde gördük ki, veri setimizdeki görüntüler farklı boyutlardadır ve modelin daha iyi genelleme yapması için veri setini yapay olarak zenginleştirmemiz gerekmektedir. Bu bölümde, görüntü verilerini modelinize uygun formata getiriyoruz.\n\n# 5.1 Eğitim/Doğrulama Ayırımı ve Boyut Standardizasyonu\nModelin performansını doğru bir şekilde ölçmek için, eğitim verilerini eğitim ve doğrulama (validation) setleri olarak ayırıyoruz. Stratejik (Stratify) ayırma kullanarak her iki setteki kedi/köpek etiketlerinin dengeli dağılmasını sağlıyoruz.\n\nAyrıca, tüm görüntüleri standart bir girdi boyutu olan 128×128 piksele yeniden boyutlandıracağız ve veriyi gruplar (Batch) halinde işleyeceğiz.\n\n# 5.2 Veri Artırma (Data Augmentation) Teknikleri\nVeri Artırma, modelin farklı açılardan, ışık koşullarından veya konumlardan gelen görüntülere karşı daha dirençli olmasını sağlar. Bu sayede modelin ezber yapması (overfitting) engellenir.\n\nEğitim seti için uygulanan temel artırma teknikleri:\n\nNormalizasyon (Rescaling): Piksel değerlerini [0,1] aralığına indirgeme.\n\nDönüşümler: Rastgele döndürme (rotation_range), yatay/dikey kaydırma (width_shift_range, height_shift_range), yakınlaştırma (zoom_range) ve yatay çevirme (horizontal_flip).\n\nDoğrulama ve test setlerine ise sadece normalizasyon uygulanır, çünkü bu setlerin gerçek dünya verisini temsil etmesi ve modelin eğitilmesine karışmaması gerekir.","metadata":{}},{"cell_type":"code","source":"# Adım 7: Veri Ön İşleme ve Hazırlık (Data Preprocessing and Augmentation)\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\n# 7.1 Görüntü Boyutu ve Batch Boyutu Ayarlama\n# Görüntü boyutlarının analizine göre uygun bir boyut seçelim.\n# Genellikle 150x150, 224x224 gibi kare boyutlar tercih edilir.\n# Veri setinizdeki boyut dağılımına bakarak karar verebiliriz.\n# Şimdilik standart bir boyut olan 128x128 ile başlayalım.\nIMAGE_SIZE = (128, 128)\nBATCH_SIZE = 32 # Bir kerede işlenecek görüntü sayısı\n\n# 7.2 Eğitim ve Doğrulama Setlerini Ayırma\n# train_df'imizi eğitim ve doğrulama (validation) setlerine ayıralım.\n# Bu, modelin görmediği veriler üzerindeki performansını değerlendirmemizi sağlar.\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['label'])\n\nprint(f\"\\nEğitim veri çerçevesi boyutu: {len(train_df)}\")\nprint(f\"Doğrulama veri çerçevesi boyutu: {len(val_df)}\")\nprint(f\"Eğitim setindeki etiket dağılımı:\\n{train_df['label'].value_counts()}\")\nprint(f\"Doğrulama setindeki etiket dağılımı:\\n{val_df['label'].value_counts()}\")\n\n# 7.3 ImageDataGenerator ile Veri Artırma ve Ön İşleme\n# Eğitim verileri için veri artırma uygulayalım\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,                 # Piksel değerlerini 0-1 aralığına normalleştir\n    rotation_range=15,              # Görüntüleri 15 dereceye kadar rastgele döndür\n    width_shift_range=0.1,          # Görüntüleri yatayda %10'a kadar kaydır\n    height_shift_range=0.1,         # Görüntüleri dikeyde %10'a kadar kaydır\n    shear_range=0.1,                # Kırpma dönüşü uygula\n    zoom_range=0.1,                 # %10'a kadar rastgele yakınlaştır\n    horizontal_flip=True,           # Yatayda rastgele çevir\n    fill_mode='nearest'             # Kaydırma veya döndürme sonrası boş kalan pikselleri doldurma modu\n)\n\n# Doğrulama ve test verileri için sadece normalizasyon uygulayalım (veri artırma yapmayız)\nval_test_datagen = ImageDataGenerator(rescale=1./255)\n\n# 7.4 Veri Üreteçlerini Oluşturma (Data Generators)\n# Bu üreteçler, model eğitimi sırasında görüntüleri otomatik olarak yükleyecek,\n# ön işleyecek ve artıracaktır.\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    directory=train_images_dir, # Görüntülerin bulunduğu dizin\n    x_col='filename',           # Görüntü dosyası isimlerini içeren sütun\n    y_col='label',              # Etiketleri içeren sütun\n    target_size=IMAGE_SIZE,     # Tüm görüntüleri bu boyuta yeniden boyutlandır\n    class_mode='categorical',   # Etiketler 'cat'/'dog' olduğu için kategorik\n    batch_size=BATCH_SIZE,\n    shuffle=True                # Eğitim verilerini karıştır\n)\n\nvalidation_generator = val_test_datagen.flow_from_dataframe(\n    val_df,\n    directory=train_images_dir, # Doğrulama setindeki görüntüler de eğitim dizininde\n    x_col='filename',\n    y_col='label',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=False               # Doğrulama verilerini karıştırmaya gerek yok\n)\n\ntest_generator = val_test_datagen.flow_from_dataframe(\n    test_df,\n    directory=test_images_dir,  # Test görüntülerinin bulunduğu dizin\n    x_col='filename',\n    y_col=None,                 # Test setinde etiket yok\n    target_size=IMAGE_SIZE,\n    class_mode=None,            # Etiket olmadığı için None\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)\n\nprint(\"\\nVeri üreteçleri başarıyla oluşturuldu.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T20:14:39.670954Z","iopub.execute_input":"2025-09-24T20:14:39.671272Z","iopub.status.idle":"2025-09-24T20:14:59.604648Z","shell.execute_reply.started":"2025-09-24T20:14:39.671244Z","shell.execute_reply":"2025-09-24T20:14:59.604060Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Evrişimli Sinir Ağı (CNN) Modelini Oluşturma\nBu bölümde, Dogs vs. Cats görüntülerini sınıflandıracak olan Evrişimli Sinir Ağı (Convolutional Neural Network - CNN) mimarisini tanımlıyoruz. CNN'ler, görüntüdeki hiyerarşik özellikleri otomatik olarak öğrenme yetenekleri sayesinde görüntü işleme görevleri için en uygun model türüdür.\n\n# 6.1 Model Mimarisi\nModelimiz, aşırı uyumu (overfitting) kontrol altında tutmak için Dropout katmanlarını içeren üç temel Evrişimsel bloktan oluşmaktadır:\n\nEvrişim (Conv2D) Katmanları: Görüntüden uzaysal özellikleri (kenarlar, dokular, şekiller) çıkarır.\n\nMaksimum Havuzlama (MaxPooling2D) Katmanları: Veri boyutunu azaltır ve modelin konum değişikliklerine karşı daha dayanıklı olmasını sağlar.\n\nDüzleştirme (Flatten) Katmanı: Evrişim katmanlarından çıkan 2D özellik haritalarını, yoğun (Dense) katmanlara beslenebilecek tek boyutlu bir vektöre dönüştürür.\n\nYoğun (Dense) Katmanlar: Sınıflandırma kararlarının verildiği geleneksel yapay sinir ağı katmanlarıdır. Son katmanımızda 2 sınıf (kedi/köpek) için softmax aktivasyonu kullanılmıştır.\n\n# 6.2 Modeli Derleme (Compilation)\nModeli eğitime başlamadan önce, öğrenme sürecini tanımlayan üç temel bileşen ile derliyoruz:\n\nOptimizer (adam): Modelin ağırlıklarını optimize etmek için popüler ve etkili bir algoritma.\n\nKayıp Fonksiyonu (categorical_crossentropy): İki sınıf arasındaki farkı ölçmek için kullanılır. Etiketlerimiz kategorik olduğu için bu fonksiyon tercih edilmiştir.\n\nMetrik (accuracy): Eğitimi izlemek için doğruluk oranı kullanılır.\n","metadata":{}},{"cell_type":"code","source":"# Adım 8: Evrişimli Sinir Ağı (CNN) Modelini Oluşturma\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Model mimarisini tanımlayalım\nmodel = Sequential([\n    # İlk Evrişim bloğu\n    Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n    MaxPooling2D((2, 2)),\n    Dropout(0.25), # Aşırı uyumu azaltmak için Dropout\n\n    # İkinci Evrişim bloğu\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Dropout(0.25),\n\n    # Üçüncü Evrişim bloğu\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Dropout(0.25),\n\n    # Görüntü özelliklerini düzleştirme\n    Flatten(),\n\n    # Yoğun (Dense) katmanlar\n    Dense(512, activation='relu'),\n    Dropout(0.5), # Aşırı uyumu daha da azaltmak için Dropout\n    Dense(2, activation='softmax') # 2 sınıf (kedi/köpek) için softmax aktivasyonu\n])\n\n# Modeli derleme\n# Optimizer: Modelin ağırlıklarını nasıl güncelleyeceğini belirler. Adam yaygın bir seçimdir.\n# Loss Function: Modelin tahminleri ile gerçek etiketler arasındaki farkı ölçer.\n#                İki sınıf ve kategorik etiketler için 'categorical_crossentropy' kullanılır.\n# Metrics: Modelin eğitim ve doğrulama sırasında izlenecek performans ölçütleri. 'accuracy' sıkça kullanılır.\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Model özetini gösterelim\nprint(\"\\nModel Mimarisi Özeti:\")\nmodel.summary()\n\n# Modeli görselleştirelim (isteğe bağlı, kurulum gerektirebilir)\n# from tensorflow.keras.utils import plot_model\n# plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n# print(\"\\nModel mimarisi 'model_architecture.png' dosyasına kaydedildi.\")\n\nprint(\"\\nCNN modeli başarıyla oluşturuldu ve derlendi.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T20:14:59.605286Z","iopub.execute_input":"2025-09-24T20:14:59.605698Z","iopub.status.idle":"2025-09-24T20:15:02.969999Z","shell.execute_reply.started":"2025-09-24T20:14:59.605681Z","shell.execute_reply":"2025-09-24T20:15:02.969258Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Model Eğitimi ve Performans İzleme\nBu bölümde, önceki aşamalarda oluşturduğumuz CNN modelini, veri artırma uygulanmış eğitim verileriyle eğitiyoruz. Eğitimi optimize etmek ve aşırı uyumu (overfitting) engellemek için Geri Çağrı (Callback) fonksiyonlarını kullanıyoruz.\n\n# 7.1 Geri Çağrı (Callback) Fonksiyonları\nEğitim sürecini otomatik olarak yönetmek için iki kritik strateji belirledik:\n\nErken Durdurma (EarlyStopping): Doğrulama Kaybı (val_loss) 10 epok boyunca iyileşme göstermezse, eğitimi otomatik olarak durdurur. Bu, modelin ezber yapmasını (overfitting) önler ve en iyi ağırlık setini geri yükler.\n\nÖğrenme Hızını Azaltma (ReduceLROnPlateau): Doğrulama Kaybı 5 epok boyunca sabit kalırsa (plato yaparsa), Öğrenme Hızını (Learning Rate) 0.2 faktörüyle çarparak düşürür. Bu, modelin daha ince ayarlamalar yapmasına ve daha derin bir yerel minimuma ulaşmasına yardımcı olabilir.\n\n# 7.2 Modeli Eğitme (model.fit)\nModeli, veri üreteçlerimizden gelen verilerle 50 epok boyunca eğitiyoruz. EarlyStopping sayesinde model, 50 epok dolmadan en iyi performansta duracaktır.","metadata":{}},{"cell_type":"code","source":"# Adım 9: Model Eğitimi (Model Training)\n\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Callbacks tanımlayalım\n# EarlyStopping: 10 epok boyunca doğrulama kaybı iyileşmezse eğitimi durdur\nearly_stopping = EarlyStopping(\n    monitor='val_loss',  # İzlenecek metrik: doğrulama kaybı\n    patience=10,         # Ne kadar süre bekleneceği (epok sayısı)\n    restore_best_weights=True # En iyi ağırlıkları geri yükle\n)\n\n# ReduceLROnPlateau: 5 epok boyunca doğrulama kaybı iyileşmezse öğrenme oranını 0.2 ile çarp\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.2,          # Öğrenme oranını bu faktörle çarp\n    patience=5,          # Ne kadar süre bekleneceği\n    min_lr=0.00001       # Minimum öğrenme oranı\n)\n\n# Modeli eğitme\n# steps_per_epoch: Her epokta eğitim verilerinden kaç adım alınacağı (toplam örnek sayısı / batch_size)\n# validation_steps: Her epokta doğrulama verilerinden kaç adım alınacağı\nhistory = model.fit(\n    train_generator,\n    epochs=50, # Başlangıçta daha fazla epok belirleyebiliriz, EarlyStopping durduracaktır\n    validation_data=validation_generator,\n    callbacks=[early_stopping, reduce_lr] # Tanımladığımız callback'leri kullan\n)\n\nprint(\"\\nModel eğitimi tamamlandı.\")\n\n# Eğitim geçmişini görselleştirelim\nprint(\"\\nEğitim geçmişi görselleştiriliyor:\")\nplt.figure(figsize=(12, 5))\n\n# Kayıp (Loss) grafiği\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Eğitim Kaybı')\nplt.plot(history.history['val_loss'], label='Doğrulama Kaybı')\nplt.title('Eğitim ve Doğrulama Kaybı')\nplt.xlabel('Epok')\nplt.ylabel('Kayıp')\nplt.legend()\nplt.grid(True)\n\n# Doğruluk (Accuracy) grafiği\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')\nplt.plot(history.history['val_accuracy'], label='Doğrulama Doğruluğu')\nplt.title('Eğitim ve Doğrulama Doğruluğu')\nplt.xlabel('Epok')\nplt.ylabel('Doğruluk')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T20:15:02.970873Z","iopub.execute_input":"2025-09-24T20:15:02.971273Z","iopub.status.idle":"2025-09-24T21:40:13.547192Z","shell.execute_reply.started":"2025-09-24T20:15:02.971239Z","shell.execute_reply":"2025-09-24T21:40:13.546293Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 8. Model Değerlendirme ve Sonuçların Sunulması\nModel eğitiminin ardından, nihai adımımız modelin performansını ölçmek ve test setimiz için tahminler oluşturmaktır. Bu adım, modelimizin gerçek dünyada ne kadar iyi genelleme yaptığını gösterir.\n\n# 8.1 Doğrulama Seti Üzerinde Değerlendirme\nEğitim sırasında izlediğimiz Doğrulama Kaybı ve Doğruluk değerlerini, modelin en iyi ağırlıkları geri yüklendikten sonra kesin olarak değerlendiriyoruz. Bu, modelimizin gördüğü verilerden bağımsız olarak ne kadar başarılı olduğunu gösteren nihai ölçümdür.\n\n# 8.2 Test Tahminlerinin Oluşturulması\nModeli, etiketleri bilinmeyen Test Seti üzerinde çalıştırarak tahminler üretiyoruz.\n\nmodel.predict(test_generator) komutu, her bir test görüntüsü için kedi ve köpek olma olasılıklarını içeren bir dizi döndürür.\n\nBu olasılıklardan en yüksek olanın indeksi (np.argmax) alınarak nihai sınıf etiketi belirlenir (0 veya 1).\n\n# 8.3 Kaggle Gönderim Dosyasının Hazırlanması\nKaggle yarışmaları, tahminlerin belirli bir formatta (genellikle submission.csv) olmasını bekler.\n\nTest görüntü dosyalarının isimlerinden ID'ler çıkarılır.\n\nTahmin edilen etiketler (0 veya 1) bu ID'lerle eşleştirilerek submission.csv dosyası oluşturulur.\n\nSon olarak, tahmin edilen bazı test görüntülerini görselleştirerek sonuçlarımızı kontrol ediyoruz.","metadata":{}},{"cell_type":"code","source":"# Adım 10: Model Değerlendirme ve Tahminler (Model Evaluation and Predictions)\n\n# 10.1 Modelin Doğrulama Seti Üzerindeki Performansını Değerlendirme\nprint(\"\\nModelin doğrulama seti üzerindeki performansı değerlendiriliyor...\")\nval_loss, val_accuracy = model.evaluate(validation_generator)\nprint(f\"Doğrulama Kaybı (Validation Loss): {val_loss:.4f}\")\nprint(f\"Doğrulama Doğruluğu (Validation Accuracy): {val_accuracy:.4f}\")\n\n# 10.2 Test Seti Üzerinde Tahminler Yapma\nprint(\"\\nTest seti üzerinde tahminler yapılıyor...\")\n# test_generator'ı kullanıyoruz\npredictions = model.predict(test_generator)\n\n# Tahmin sonuçları, her bir görüntü için 'cat' ve 'dog' olma olasılıklarını içerir.\n# Örneğin: [0.9, 0.1] -> %90 kedi, %10 köpek\n#         [0.2, 0.8] -> %20 kedi, %80 köpek\n\n# En yüksek olasılığa sahip sınıfın indeksini alalım (0 veya 1)\npredicted_class_indices = np.argmax(predictions, axis=1)\n\n# Sınıf isimlerini alalım (ImageDataGenerator'dan)\nlabels = (train_generator.class_indices) # {'cat': 0, 'dog': 1}\nlabels = dict((v, k) for k, v in labels.items()) # {'0': 'cat', '1': 'dog'}\npredicted_labels = [labels[k] for k in predicted_class_indices]\n\n# 10.3 Tahminleri Kaggle Gönderim Formatına Hazırlama\n# Kaggle'da genellikle submission.csv dosyası istenir: id, label\n# Test dosyası isimleri 'id.jpg' formatında olduğu için sadece id kısmını almalıyız.\n\n# test_df'den dosya adlarını al ve '.jpg' uzantısını kaldırarak id'leri çıkar\ntest_ids = [int(os.path.splitext(filename)[0]) for filename in test_df['filename']]\n\n# Tahminleri ve id'leri içeren bir DataFrame oluştur\nsubmission_df = pd.DataFrame({\n    'id': test_ids,\n    'label': predicted_class_indices # 0 veya 1 olarak etiketleri kullan (Kaggle genellikle bunu bekler)\n                                     # Eğer 'cat' veya 'dog' olarak string isteniyorsa, predicted_labels'ı kullanın.\n})\n\n# Kaggle'ın genellikle beklediği 0 (kedi) ve 1 (köpek) formatında etiketler.\n# Bazı yarışmalarda olasılıklar da istenebilir (örneğin kedi için olasılık).\n# Bu projede genellikle 0 veya 1 istenir, 0.5'ten küçükler kedi, büyükler köpek gibi.\n# Bizim modelimiz 0. indeks kediyi, 1. indeks köpeği temsil ediyor.\n# Yani 0: cat, 1: dog.\n\n# Submission dosyasını kaydetme\nsubmission_df.to_csv('submission.csv', index=False)\n\nprint(\"\\nTahminler tamamlandı ve 'submission.csv' dosyası oluşturuldu.\")\nprint(\"Submission dosyasının ilk 5 satırı:\")\nprint(submission_df.head())\n\n# İsteğe bağlı: Tahmin edilmiş bazı test görüntülerini gösterelim\nprint(\"\\nTest setinden rastgele 9 örnek tahmin:\")\nplt.figure(figsize=(12, 12))\nfor i in range(9):\n    random_index = np.random.randint(0, len(test_df))\n    filename = test_df.iloc[random_index]['filename']\n    img_path = os.path.join(test_images_dir, filename)\n\n    img = Image.open(img_path)\n    predicted_label_str = predicted_labels[random_index] # String etiket\n    \n    plt.subplot(3, 3, i + 1)\n    plt.imshow(img)\n    plt.title(f\"Tahmin: {predicted_label_str}\")\n    plt.axis('off')\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nTebrikler, 'Dogs vs. Cats' projesinin temel adımlarını başarıyla tamamladın!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T21:42:58.438798Z","iopub.execute_input":"2025-09-24T21:42:58.439117Z","iopub.status.idle":"2025-09-24T21:43:24.127833Z","shell.execute_reply.started":"2025-09-24T21:42:58.439092Z","shell.execute_reply":"2025-09-24T21:43:24.126819Z"}},"outputs":[],"execution_count":null}]}